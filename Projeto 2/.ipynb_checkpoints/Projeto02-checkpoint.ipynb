{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 13/Set até às 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "Até o dia 06 de Setembro às 23:59, o notebook e o xlsx devem estar no Github com as seguintes evidências: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste já classificado.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conexão com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "#!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que serão utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados é necessário ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***\n",
    "\n",
    "\n",
    "1. Caso ainda não tenha uma: https://twitter.com/signup\n",
    "1. Depois é necessário registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote também:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATENÇÃO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele contém as chaves necessárias para realizar as operações no twitter de forma automática e portanto é equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as operações manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo não precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @MathDuarth\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, não haverá uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Annabelle_2'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora você deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem é relevante ou não.<br /> \n",
    "Não se esqueça de colocar um nome para a coluna na célula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu código abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "from operator import mul\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\vf_ga\\OneDrive\\Documentos\\2º Semestre Eng\\Ciencia dos Dados\\GIT\\CienciaDosDados\\Projeto 2\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @omelete: emoji - o filme ultrapassa annabe...</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acho que vou ver annabelle 2 quinta \\no cu já ...</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@raffaimp annabelle 2, quinta-feira 18:40. fec...</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nunca tive tanta vontade de ir ao cinema, quan...</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>annabelle 2 deixou mt desejar, está mt sletzinho</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento Relevancia\n",
       "0  rt @omelete: emoji - o filme ultrapassa annabe...        Não\n",
       "1  acho que vou ver annabelle 2 quinta \\no cu já ...        Sim\n",
       "2  @raffaimp annabelle 2, quinta-feira 18:40. fec...        Sim\n",
       "3  nunca tive tanta vontade de ir ao cinema, quan...        Sim\n",
       "4   annabelle 2 deixou mt desejar, está mt sletzinho        Sim"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dadosTreinamento = pd.read_excel('Annabelle_2.xlsx', sheetname=\"Treinamento\")\n",
    "dadosTreinamento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    rt @omelete: emoji - o filme ultrapassa annabe...\n",
       "1    acho que vou ver annabelle 2 quinta \\no cu já ...\n",
       "2    @raffaimp annabelle 2, quinta-feira 18:40. fec...\n",
       "3    nunca tive tanta vontade de ir ao cinema, quan...\n",
       "4     annabelle 2 deixou mt desejar, está mt sletzinho\n",
       "Name: Treinamento, dtype: object"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dadosTreinamento.Treinamento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    rt @omelete: emoji  filme ultrapassa annabelle...\n",
       "1    acho que vou ver annabelle 2 quinta \\no cu já ...\n",
       "2      @raffaimp annabelle 2 quintafeira 18:40 fechou \n",
       "3    nunca tive tanta vontade de ir ao cinema quant...\n",
       "4      annabelle 2 deixou mt desejar está mt sletzinho\n",
       "Name: Treinamento, dtype: object"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dadosTreinamento['Treinamento'] = dadosTreinamento['Treinamento'].str.replace(\",\",\"\")\n",
    "dadosTreinamento['Treinamento'] = dadosTreinamento['Treinamento'].str.replace(\".\",\"\")\n",
    "dadosTreinamento['Treinamento'] = dadosTreinamento['Treinamento'].str.replace(\"'\",\"\")\n",
    "dadosTreinamento['Treinamento'] = dadosTreinamento['Treinamento'].str.replace('\"',\"\")\n",
    "dadosTreinamento['Treinamento'] = dadosTreinamento['Treinamento'].str.replace(\"-\",\"\")\n",
    "dadosTreinamento['Treinamento'] = dadosTreinamento['Treinamento'].str.replace(\"!\",\"\")\n",
    "dadosTreinamento['Treinamento'] = dadosTreinamento['Treinamento'].str.replace(\"?\",\"\")\n",
    "dadosTreinamento['Treinamento'] = dadosTreinamento['Treinamento'].str.replace(\")\",\"\")\n",
    "dadosTreinamento['Treinamento'] = dadosTreinamento['Treinamento'].str.replace(\"(\",\"\")\n",
    "dadosTreinamento['Treinamento'] = dadosTreinamento['Treinamento'].str.replace(\" a \",\" \")\n",
    "dadosTreinamento['Treinamento'] = dadosTreinamento['Treinamento'].str.replace(\" as \",\" \")\n",
    "dadosTreinamento['Treinamento'] = dadosTreinamento['Treinamento'].str.replace(\" o \",\" \")\n",
    "dadosTreinamento['Treinamento'] = dadosTreinamento['Treinamento'].str.replace(\" os \",\" \")\n",
    "dadosTreinamento['Treinamento'] = dadosTreinamento['Treinamento'].str.lower()\n",
    "\n",
    "dadosTreinamento.Treinamento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naoRelevante=[]\n",
    "relevante=[]\n",
    "naoRelevanteSplit=[]\n",
    "relevanteSplit=[]\n",
    "listaTodasIrrelevantes=[]\n",
    "listaTodasRelevantes=[]\n",
    "listaTodasIrrelevantes=[]\n",
    "universoGeral=[]\n",
    "universoRelevanteSemRepeticao=[]\n",
    "universoIrrelevanteSemRepeticao=[]\n",
    "contandoCadaRelevante = {}\n",
    "contandoCadaIrrelevante = {}\n",
    "contantoProbabilidadeCadaPalavraRelevante = {}\n",
    "contantoProbabilidadeCadaPalavraIrrelevante = {}\n",
    "\n",
    "for i in range(len(dadosTreinamento.Treinamento)):\n",
    "    if dadosTreinamento.Relevancia[i] == \"Não\":\n",
    "        naoRelevante.append(dadosTreinamento.Treinamento[i])\n",
    "    if dadosTreinamento.Relevancia[i] == \"Sim\":\n",
    "        relevante.append(dadosTreinamento.Treinamento[i])\n",
    "\n",
    "for i in naoRelevante:\n",
    "    split = i.split()\n",
    "    naoRelevanteSplit.append(split)\n",
    "\n",
    "for i in relevante:\n",
    "    split = i.split()\n",
    "    relevanteSplit.append(split)\n",
    "    \n",
    "for i in relevanteSplit:\n",
    "    for u in i:\n",
    "        listaTodasRelevantes.append(u)\n",
    "\n",
    "for i in naoRelevanteSplit:\n",
    "    for u in i:\n",
    "        listaTodasIrrelevantes.append(u)\n",
    "        \n",
    "for i in listaTodasRelevantes:\n",
    "    total=listaTodasRelevantes.count(i)\n",
    "    contandoCadaRelevante[i] = total\n",
    "\n",
    "for i in listaTodasIrrelevantes:\n",
    "    total=listaTodasIrrelevantes.count(i)\n",
    "    contandoCadaIrrelevante[i] = total\n",
    "    \n",
    "universoGeral.extend(listaTodasIrrelevantes)\n",
    "universoGeral.extend(listaTodasRelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Geral\n",
    "universoGeralSemRepeticao = set(universoGeral)\n",
    "numeroGeralSemRepeticao = len(universoGeralSemRepeticao)\n",
    "\n",
    "#Relevante\n",
    "numeroRelevantesComRepeticao = len(listaTodasRelevantes)\n",
    "universoRelevanteSemRepeticao = set(listaTodasRelevantes)\n",
    "numeroRelevanteSemRepeticao = len(universoRelevanteSemRepeticao)\n",
    "\n",
    "#Irrelevante\n",
    "numeroIrrelevanteComRepeticao = len(listaTodasIrrelevantes)\n",
    "universoIrrelevanteSemRepeticao = set(listaTodasIrrelevantes)\n",
    "numeroIrrelevanteSemRepeticao = len(universoIrrelevanteSemRepeticao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "863\n",
      "547\n",
      "453\n",
      "1640\n",
      "2334\n"
     ]
    }
   ],
   "source": [
    "#serie_todas = pd.Series(universoGeral)\n",
    "print(numeroGeralSemRepeticao)\n",
    "print(numeroRelevanteSemRepeticao)\n",
    "print(numeroIrrelevanteSemRepeticao)\n",
    "print(univerRelevantesComRepetiçao)\n",
    "print(universoIrrelevanteComRepeticao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in universoRelevanteSemRepeticao:\n",
    "    contantoProbabilidadeCadaPalavraRelevante[i] = (contandoCadaRelevante[i] + 1) / (numeroRelevantesComRepeticao + numeroGeralSemRepeticao)\n",
    "\n",
    "for i in universoIrrelevanteSemRepeticao:\n",
    "    contantoProbabilidadeCadaPalavraIrrelevante[i] = (contandoCadaIrrelevante[i] + 1) / (numeroIrrelevanteComRepeticao + numeroGeralSemRepeticao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fui ver annabelle 2, e os sustos veio a tona k...</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annabelle 2 tinha de tudo pra ser bom\\nfinal ruim</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @omelete: emoji - o filme ultrapassa annabe...</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>annabelle 2 é pesado, meu deus</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @vemprovictor: vocês acharam annabelle 2 as...</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste Relevancia\n",
       "0  fui ver annabelle 2, e os sustos veio a tona k...        Sim\n",
       "1  annabelle 2 tinha de tudo pra ser bom\\nfinal ruim        Sim\n",
       "2  rt @omelete: emoji - o filme ultrapassa annabe...        Não\n",
       "3                     annabelle 2 é pesado, meu deus        Sim\n",
       "4  rt @vemprovictor: vocês acharam annabelle 2 as...        Não"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dadosTeste = pd.read_excel('Annabelle_2.xlsx', sheetname=\"Teste\")\n",
    "dadosTeste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       fui ver annabelle 2 e sustos veio tona kkkkkkk\n",
       "1    annabelle 2 tinha de tudo pra ser bom\\nfinal ruim\n",
       "2    rt @omelete: emoji  filme ultrapassa annabelle...\n",
       "3                        annabelle 2 é pesado meu deus\n",
       "4    rt @vemprovictor: vocês acharam annabelle 2 as...\n",
       "Name: Teste, dtype: object"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dadosTeste['Teste'] = dadosTeste['Teste'].str.replace(\",\",\"\")\n",
    "dadosTeste['Teste'] = dadosTeste['Teste'].str.replace(\".\",\"\")\n",
    "dadosTeste['Teste'] = dadosTeste['Teste'].str.replace(\"'\",\"\")\n",
    "dadosTeste['Teste'] = dadosTeste['Teste'].str.replace('\"',\"\")\n",
    "dadosTeste['Teste'] = dadosTeste['Teste'].str.replace(\"-\",\"\")\n",
    "dadosTeste['Teste'] = dadosTeste['Teste'].str.replace(\"!\",\"\")\n",
    "dadosTeste['Teste'] = dadosTeste['Teste'].str.replace(\"?\",\"\")\n",
    "dadosTeste['Teste'] = dadosTeste['Teste'].str.replace(\")\",\"\")\n",
    "dadosTeste['Teste'] = dadosTeste['Teste'].str.replace(\"(\",\"\")\n",
    "dadosTeste['Teste'] = dadosTeste['Teste'].str.replace(\" a \",\" \")\n",
    "dadosTeste['Teste'] = dadosTeste['Teste'].str.replace(\" as \",\" \")\n",
    "dadosTeste['Teste'] = dadosTeste['Teste'].str.replace(\" o \",\" \")\n",
    "dadosTeste['Teste'] = dadosTeste['Teste'].str.replace(\" os \",\" \")\n",
    "dadosTeste['Teste'] = dadosTeste['Teste'].str.lower()\n",
    "\n",
    "dadosTeste.Teste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listaTeste = []\n",
    "tweetEmProbabilidade = []\n",
    "listaProbabilidadeRevelanteTweet = []\n",
    "listaProbabilidadeIrrevelanteTweet = []\n",
    "\n",
    "for i in dadosTeste.Teste:\n",
    "    splitTeste= i.split()\n",
    "    listaTeste.append(splitTeste)\n",
    "\n",
    "\n",
    "for tweet in listaTeste:\n",
    "    for palavra in tweet:\n",
    "        if palavra in universoRelevanteSemRepeticao:\n",
    "            tweetEmProbabilidade.append(contantoProbabilidadeCadaPalavraRelevante[palavra])\n",
    "        else:\n",
    "            valor = 1 / (numeroRelevanteSemRepeticao + numeroGeralSemRepeticao)\n",
    "            tweetEmProbabilidade.append(valor)\n",
    "    listaProbabilidadeRevelanteTweet.append(reduce(mul,tweetEmProbabilidade))\n",
    "    del tweetEmProbabilidade [:]\n",
    "\n",
    "for tweet in listaTeste:\n",
    "    for palavra in tweet:\n",
    "        if palavra in universoIrrelevanteSemRepeticao:\n",
    "            tweetEmProbabilidade.append(contantoProbabilidadeCadaPalavraIrrelevante[palavra])\n",
    "        else:\n",
    "            valor = 1 / (numeroIrrelevanteSemRepeticao + numeroGeralSemRepeticao)\n",
    "            tweetEmProbabilidade.append(valor)\n",
    "    listaProbabilidadeIrrevelanteTweet.append(reduce(mul,tweetEmProbabilidade))\n",
    "    del tweetEmProbabilidade [:]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listaFinalRelevancia = []\n",
    "for i in range(len(listaTeste)):\n",
    "    if listaProbabilidadeRevelanteTweet[i] > listaProbabilidadeIrrevelanteTweet[i]:\n",
    "        listaFinalRelevancia.append('Sim')\n",
    "    if listaProbabilidadeRevelanteTweet[i] < listaProbabilidadeIrrevelanteTweet[i]:\n",
    "        listaFinalRelevancia.append('Não')\n",
    "    if listaProbabilidadeRevelanteTweet[i] == listaProbabilidadeIrrevelanteTweet[i]:\n",
    "        listaFinalRelevancia.append('Neutro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dadosTeste[\"Respostas\"] = pd.Series(listaFinalRelevancia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listaResultados = []\n",
    "for i in range(len(listaFinalRelevancia)):\n",
    "    if dadosTeste.Respostas[i] == \"Sim\"  and dadosTeste.Relevancia[i] == \"Sim\":\n",
    "        listaResultados.append(\"Positivo\")\n",
    "    if dadosTeste.Respostas[i] == \"Não\"  and dadosTeste.Relevancia[i] == \"Sim\":\n",
    "        listaResultados.append(\"Falso Negativo\")\n",
    "    if dadosTeste.Respostas[i] == \"Sim\"  and dadosTeste.Relevancia[i] == \"Não\":\n",
    "        listaResultados.append(\"Falso Positivo\")\n",
    "    if dadosTeste.Respostas[i] == \"Não\"  and dadosTeste.Relevancia[i] == \"Não\":\n",
    "        listaResultados.append(\"Negativo\")\n",
    "        \n",
    "dadosTeste[\"Analise\"] = pd.Series(listaResultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negativo          41.5\n",
       "Positivo          40.5\n",
       "Falso Positivo    11.5\n",
       "Falso Negativo     6.5\n",
       "Name: Analise, dtype: float64"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Porcentagem de Negativos, Positivos, Falsos Postivos e Falsos Negativos\n",
    "(dadosTeste.Analise.value_counts(normalize=True)*100).round(decimals=1).reindex(['Negativo', 'Positivo', 'Falso Positivo', 'Falso Negativo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('Testanto Robo.xlsx', engine='xlsxwriter')\n",
    "dadosTeste.to_excel(writer, sheet_name='Robo e Comparação')\n",
    "worksheet = writer.sheets['Robo e Comparação']\n",
    "worksheet.set_column('A:A', None)\n",
    "worksheet.set_column('B:B', 120)\n",
    "worksheet.set_column('C:C', 15)\n",
    "worksheet.set_column('D:D', 15)\n",
    "worksheet.set_column('E:E', 15)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Após vários testes com os twitters de usuários foi possível ensinar ao computador como dizer se um certo twitter seria relevante ou não ao produto escolhido. Escolhemos o filme Annabelle 2, que como foi recém lançado estava em alta no twitter, e queríamos saber se as pessoas estavam indo ao cinema, e quando iam o que achavam do filme (se era melhor que o primeiro, se valia a pena ver, etc...), esses seriam os nossos twitter relevantes; enquanto twitter que não remetiam diretamente ao fato de uma pessoa ter ido ver o filme seriam considerados irrelevantes. Após essa separação fizemos a contagem de palavras de cada uma dessas listas (relevantes e irrelevantes) e aplicamos o Teorema de Bayes para criar o nosso Classificador Naive-Bayes. Com esse classificador pronto foi possível rodar novas listas teste sobre o filme e deixar que a máquina dissesse se os twitters recebidos eram relativos ou não, e assim foi possível comparar a saída dela com nosso conceito de relevância.\n",
    "\n",
    "Vamos à comparação dos dados. De todos os twitters passados para o máquina; ela retornou 41,5% como negativos verdadeiros (que batem com o conceito pré-definido de irrelevância), 40,5% como positivos verdadeiros (que batem com o conceito pré-definido de relevância), 11,5% como positivos falsos (que são twitters considerados relevantes para a máquina mas não para nosso conceito) e 6,5% de negativos falsos (que são twitters considerados irrelevantes para a máquina mas são relevantes para nosso conceito). A máquina não teve 100% de acerto, mas ela também não foi 100% errada, teve exatamente 82% de acerto em relação ao conceito pré-definido de relevância e de irrelevância. Os 18% de erro podem ser considerados esperados, já que através do contador nós mostramos para a máquina a relevância de certas palavras, e muitas vezes elas podem ser intercaladas entre twitters relevantes e irrelevantes, assim \"confundindo\" a máquina e fazendo com que ela caracterize erroneamente alguns twitters.\n",
    "\n",
    "Esses erros podem ser observados em twitters sarcásticos ou com dupla negação, como por exemplo: \"ia assistir annabelle 2 hj mas pensei não vou gastar dinheiro\". Esse twitter tem várias palavras que caem mais na parte da relevância do que da irrelevância, como: \"assistir\", \"Annabelle\", \"hj\", \"2\". Isso faz que com o contador acuse essa frase como relevante, o que para nós não é, pois queremos saber o que as pessoas estão achando do filme. Essas frases \"confundem\" o contador, pois ele não foi treinado para detectar sarcasmo ou dupla negação. Por isso também que fazemos uma primeira deifinição dos twitters à mão, para que seja possível comparar com as saídas feitas pela máquina, e assim acusar os positivos falsos e os negativos falsos, para que seja possível tirá-los do possível resultado, e assim apenas analisar os dados que batem com a definição.\n",
    "\n",
    "Bem, como expansão podemos fazer algumas mudanças no projeto. Primeiro podemos começar aumentando o número de twitters recebidos e mandandos para a máquina, assim aumetando o número de palavras conhecidas no contador de Bayes (quanto mais palavras menos Laplace Smoothing será utilizado) para que ele seja cada vez mais preciso. Também podemos criar uma nova parte do projeto apenas do primeiro filme, para que possamos comparar diretamente os twitters antigos sobre o primeiro filme com os novos, tendo mais precisão na hora de saber sobre qual ficou melhor, e o que ainda há de melhorar. O financiamento deve continuar para o projeto para que seja possível continuar a pesquisa sobre a satisfação que o filme está trazendo as pessoas, e sobre formas de melhorar uma possível sequência. Financiar esse projeto pode trazer um grande lucro para uma sequência do filme (para que acertem no que colocar ou não no filme), ou salvar a empresa de um grande prejuízo se lançarem uma sequência que ninguém pediu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
